---
title: Design of Experiments
---

# Research Design

## Observational vs. Experimental
The fundamental difference between observational studies and experimental research designs is that in the former, researchers simply observe and measure variables without actively intervening. In the latter, variables are purposefully manipulated to determine a cause-and-effect relationship.

## Randomization
The effect and aim of randomisation is to eliminate selection bias and confounding factors, and to ensure comparability between groups at the start of the study (baseline data).

## Confounder
Confounding occurs when a factor (confounder) that has not been investigated is associated with both the independent and dependent variables, causing a spurious correlation between them.

## Blinding
The problem is distortion due to knowledge about the treatment. Blinding is a suitable technique for avoiding such distortions. It eliminates conscious and unconscious influences on the treatment result.

### Types of blining

- Open: No blining
- Single-blind: Participants don't know their group assignment (e.g., whether they're receiving the real treatment or a placebo).
- Double-blind: Neither the participants nor the researchers administering the treatment know the group assignments.
- Triple-blind: Participants, researchers, and the data analysts are all unaware of the group assignments.

# Principles

##  Introduction to scientific theory

### Scientific Theory

Examines whether and how scientific knowledge can be obtained. It is a branch of philosophy that deals with the theory of scientific knowledge and scientific methods, as well as with research. It also analyzes the practices that generate scientific knowledge and examines the institutional and social contexts in which these take place.

### Methodology

It focuses on the underlying considerations, decisions, and justifications of the approach used in scientific research projects. It provides the instructional framework on how to proceed in order to gain scientific knowledge. It does not comprise a strictly formal set of rules but offers a diverse and pragmatic set of choices that are linked to human action.

### Research Methodes

Systematized procedures and approaches for obtaining knowledge.

### Selection of positions held in scientific theory

- Classical rationalism: Reason precedes experience and there are so-called "innate" concepts of reason.
- Inductive empiricism: Findings are derived inductively based on observations and experiences.
- Logical positivism: The use of logic makes it possible to separate science from metaphysics.
- Critical rationalism: Findings are derived deductively based on observations.
- (Social) constructivism: Individuals construct their reality by relating their thinking and actions.

> Note: Inductive empiricism and critical rationalism belong to empirical research.

### What is empirical research?

Knowledge can be gained only through observation, experiment, and experience. Empirical research examines the environment by means of observation and experiment. There are many research methods for conducting observations and experiments:

- Interview
- Case study
- Survey study
- Experiment

### Landscape of empirical research

![Landscape of empirical research](img/landscape_of_empirical_research.png)

### Quantitative Methodes

Research that uses quantitative methods is designed around the principles of critical rationalism. The approach assumes that a theory can never be finally verified, it can only be falsified.

### Descriptive statistics

- Describes the data to be analyzed.
- Is limited to a sample as a subset of the population.
- Does not allow for conclusions to be drawn about the population.

### Inferential statistics

- For drawing conclusions about the population based on information obtained from a sample.
- Use statistical hypothesis tests, especially, as the main component.

### Hypothesis Testing

Hypothesis testing is a statistical method used to determine if there is enough evidence in a sample of data to support a specific hypothesis about a population. It involves formulating a null hypothesis and an alternative hypothesis, analyzing sample data, and making a decision based on the results, often using a p-value to assess significance.

- Alternative hypothesis ($H_A$): Research hypothesis to be tested that postulates the presence of a certain effect (e.g. a difference) in the population.
- Null hypothesis ($H_0$): Postulates the opposite, namely the absence of an effect.

## Research process

### Phases

1. Formulation of the research problem & study design
2. Planning and preparation of the study
3. Data collection
4. Data Analysis
5. Reporting

### Measuring Instrument

A process that uses a given set of circumstances to define and specify subsequent research steps with a view to better understanding these circumstances.

### Sampling procedure

A selection of cases derived from the population and compiled for research purposes results in statements as part of an empirical study. Sampling often involves people, but objects of all kinds (e.g., websites, newspaper articles, companies, countries) can also form a population. Sample surveys are typical of empirical social research. Only rarely are censuses used that examine all cases associated with the population.

## Definition & properties of study design

The choice of a suitable research design determines the scientific quality of a study. The planning of the analysis depends on the research design.

### Study types

- Descriptive study: Descriptive character. Suitable for forming hypotheses (Surveys).
- Analytical study: Identification and quantification of effects / verification of relationships. Not fully suitable for hypothesis testing (Cohot).
- Randomized controlled: Suitable for hypothesis testing (RCT).

# Lecture 03: Introduction to Design of Experiments (DoE)

## Cause and Effect

A trial / experiment is carried out to discover a cause-and-effect relationship in a process.

### Terms

- Input: Trial objects, test objects, test persons, ect.
- Process: Process in which controllable and non-controllable factors influence the input.
- Output (aka. Dependet variable: DV): Input changed by the process, result of the test/experiment.
- Controllable factors (aka Independet variables: IV): Influencing factors whose strength can be adjusted within defined limits.
- Non-controllable factors: Influencing factors whose strength cannot be determined but that can be measured / cannot be determined and that cannot be measured.

## Non-controllable factors

Non-controllable factors are also referred to as nuisance variables in a general context or nuisance factors in the context of blocking

> Note: Blocking = arranging of experimental units in groups (blocks)

## Causality in observational and experimental study designs

Observational studies cannot directly prove causality, but only show correlations or associations. Since the assignment is not random, there is always a risk that the results are distorted by unknown confounding factors.

Experimental studies (e.g. RCTs) can prove causality because they control for confounding factors through randomisation, thereby isolating the effect of the cause. They are the gold standard.

## Variance

The variance describes the mean square deviation of the individual measured values from the empirical mean.

- Primary variance: Impact of (experimental) factors in an experiment on
the change / variation of the output to be examined.
- Secondary variance: Variation of the output to be examined, caused by nuisance variables.
Not in the focus of the study.
- Error variance: Variation caused by measurement errors and random processes.

> Note: Secondary and error variances are grouped to the residual variance.

### Variantion of Variance

The variance of the dependent variable (DV) (primary variance) should be attributed to the systematic variation of the independent variable (IV). The secondary variance should be controlled and the error variance minimized.

![Summary Variance](img/var_summary.png)

#### Maximizing the primary variance

- Relationship is linear: Selecting of extreme values in the IV. 
- Relationship were curvilinear: Selecting optimal increments of IV.
- Relationship were unknown: Selecting as many increments of IV in the smallest steps as possible.

#### Control of the secondary variance

- Keeping constant: Keeping the experimental setup constant.
- Repetition: Several measurements are repeated on the same trial objects.
- Randomization: Trial objects are assigned randomly to Treatment and Control groups to eliminate systematic bias
- Blocking: Trial objects are grouped into homogeneous blocks based on one or more influential
variables to reduce variability.
- Covariate adjustment: Nuisance variables are included as covariates in the statistical model to account for their effects.

#### Minimizing the error variance

- Reliable measurement setup: Standardization of the experimental conditions
- Sample size: Larger sample sizes reduce the impact of individual measurement errors
- Suitable analytical methods: Use of robust estimators to account for heterogeneous error variance

### Properties of measurement instruments

- Objectivity: Objectivity of an instrument is given when the results are independent of personnel and calculation methods.
- Reliability: Reliability is the degree to which an instrument produces the same result each time under comparable conditions.
- Validity: Validity is the extent to which an instrument measures what was intended.

# Lecture 04: Properties of DoE

## Design of Experiments Types

### Trial and error

Combination of parameters have no structure and are mixed randomly. No idea what factors influence how.

### One-factor-at-a-time

Vary the first factor and then measure fuel consumption. Keep the setting with the lowest consumption and then vary the next factor. Easy to implement, but interaction between factors are not recognized. Research question is answered neither systematically nor exhaustively.

### Full factorial design

Two levels (+/-) are defined per factor. All possible combinations of factor levels are varied. All main effects and all interactions can be determined. Can be used as a screening experiment to identify potentially important variables. The effort involved increases rapidly as the number of factors increases. Each additional factor doubles the number of combinations.

#### Profile Plot

Impact of the factors on the dependent variable $x$. Based model:

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 \dots + \beta_n x_n 
$$

## Factorial design with interactions

Interactions can occur in experiments with two or more independent variables. An interaction of two factors means that the two factors interact in a complex way. If there is an interaction, the effect of one factor depends on the levels of the other factor. Interaction terms are written as multiplication.

- Two way interaction: $x_1 \times x_2$
- Three way interaction: $x_1 \times x_2 \times x_3$

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 \times x_2
$$

### Full factorial designs
Generalization of two-level full factorial design with $k$ factors and $n$ levels. All possible factor combinations are varied.

$$
\text{combinations} = n^k
$$

### Fractional factorial designs

Only a (balanced) part of the possible combinations of factors are varied.

$$
\text{combinations} = n^{k-1}
$$

#### Design

- Procedure: The factor levels are determined before the experiment
- Factor combinations: Only a part of the possible combinations of factors are selected
- Restrictions: In fractional factorial designs, interactions can only be partially measured because not all possible combinations of factor levels are tested.
- Advantages: The effort involved is significantly lower compared to full factorial designs
- Statistical analysis: As in the case of full factorial design, but without interactions

## Quality criteria of experiments

### Internal Validity

Exists when changes in dependent variables (DV) are attributed to independent variables (IV). Increases with decreasing impact of nuisance variables.

#### Population Validity

Degree to which the results of a study can be generalized from the sample to the whole population.

#### Situation Validity

Degree to which the findings of a study can be applied to different situations.

### External Validity

Exists when experimental results from a sample can be generalized to the entire population. Increases with increasing naturalness.

### Construct Validity

Effectiveness of the measurement methods in precisely capturing the intended construct

### Relationship between Internal vs. External Validity

![Relationship between Internal vs. External Validity](img/internal_vs_external_validity.png)

The lowest general level of validity is at the bottom left for the quasi-experimental laboratory study, and the highest is at the top right for the experimental field study. A well-controlled lab experiment may maximize internal validity by eliminating confounding variables.
