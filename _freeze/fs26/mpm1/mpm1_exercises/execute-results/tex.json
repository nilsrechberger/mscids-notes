{
  "hash": "9a66ec232183c62d8cc4872641eebd29",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Applied Machine Learning and Predictive Modelling 1 - Exercises\nauthor: Nils Rechberger\ndate: 2026-02-21\n---\n\n\n\n\n\n\n# Series 1: Linear Models\n\nIn class we fitted a model to the “cats” dataset. You may remember that the interpretation of the intercept was somehow problematic. Let’s get the data, visualise it and refit the model again.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd.cats <- read.csv(\n    file = \"/home/nils/dev/mscids-notes/fs26/mpm1/data/Cats.csv\",\n    header = TRUE,\n    stringsAsFactors = TRUE\n    )\n\nstr(d.cats)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t144 obs. of  3 variables:\n $ Sex         : Factor w/ 2 levels \"F\",\"M\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Body.weight : num  2 2 2 2.1 2.1 2.1 2.1 2.1 2.1 2.1 ...\n $ Heart.weight: num  7 7.4 9.5 7.2 7.3 7.6 8.1 8.2 8.3 8.5 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(d.cats)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Sex Body.weight Heart.weight\n1   F         2.0          7.0\n2   F         2.0          7.4\n3   F         2.0          9.5\n4   F         2.1          7.2\n5   F         2.1          7.3\n6   F         2.1          7.6\n```\n\n\n:::\n:::\n\n\n\n\n\n\nLet’s display the effect of Body.weight.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(Heart.weight ~ Body.weight, data = d.cats)\n```\n\n::: {.cell-output-display}\n![](mpm1_exercises_files/figure-pdf/unnamed-chunk-2-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\nThe first model we fitted was:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm.cats <- lm(Heart.weight ~ Body.weight, data = d.cats)\n```\n:::\n\n\n\n\n\n\nThe estimated coefficients of this model are:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(lm.cats)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept) Body.weight \n -0.3566624   4.0340627 \n```\n\n\n:::\n:::\n\n\n\n\n\n\nAs mentioned in class, the correct interpretation of the intercept is “a cat with zero body.weight, is expected to have a heart weight of -0.36”. It is obviously nonsensical for two reasons:\n\n1. There is no cat of zero body weight\n2. A negative prediction for the response variable heart.weight is impossible in reality.\n\n## Questions\n\n### Question 1\n\nHow would you proceed to simplify the interpretation of the intercept in this model? Hint: try to manipulate the predictor body.weight (e.g. by centering it).\n\n#### Answer\n\nBy centering the variable `Body.weight`, we can get a interpretable intercept.\n\n$$\n\\text{Body.weight.cent} = \\text{Body.weight} - \\bar{x}\n$$\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd.cats$Body.weight.cent <- d.cats$Body.weight - mean(d.cats$Body.weight)\nplot(Heart.weight ~ Body.weight.cent, data = d.cats)\n```\n\n::: {.cell-output-display}\n![](mpm1_exercises_files/figure-pdf/unnamed-chunk-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n### Question 2\n\nLet’s turn our attention to the model that contains sex too, but no interaction. Reparametrise this model such that \"M\" is the reference. Hint: use the relevel() function.\n\n#### Answer\n\nFirst we check the current level of `Sex`.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(d.cats$Sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"F\" \"M\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\nWe can see that `F` ist the reference level. To change that:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd.cats$Sex <- relevel(x = d.cats$Sex, ref = \"M\")\nlevels(d.cats$Sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"M\" \"F\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\nNow we need to refit our model:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm.cats.relevelled <- lm(Heart.weight ~ Body.weight + Sex, data = d.cats)\ncoef(lm.cats.relevelled)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept) Body.weight        SexF \n-0.49704946  4.07576892  0.08209684 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n### Question 3\n\nWhen the predictor sex was added to the model, the estimated coefficient for ‘body.weight‘ slightly changed. Refit both models, show the estimated coefficients and write a sentence that correctly describes their \"biological interpretation\" of the Body.weight predictor in each model.\n\n#### Answer\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"Ceoff for without sex:\", coef(lm.cats), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCeoff for without sex: -0.3566624 4.034063 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Ceoff for with sex:\", coef(lm.cats.relevelled))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCeoff for with sex: -0.4970495 4.075769 0.08209684\n```\n\n\n:::\n:::\n\n\n\n\n\n\n- First model: By increasing by one unit body weight, we expect an increase of 4.03 in the response variable.\n- Second model: By increasing by one unit body weight, while keeping all the other predictors fixed, we expect an increase of 4.08 in the response\nvariable.\n\n### Question 4\n\nThis time we assume that Body.weight was not provided as a continuous variable, but rather as a categorical one. We do this by creating four classes with similar size. With this purpose in mind, we use the `quantil()` and `cut()` functions.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantiles.Body.weight <- quantile(d.cats$Body.weight)\nquantiles.Body.weight\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   0%   25%   50%   75%  100% \n2.000 2.300 2.700 3.025 3.900 \n```\n\n\n:::\n\n```{.r .cell-code}\nd.cats$Body.weight.Class <- cut(\n    x = d.cats$Body.weight,\n    breaks = quantiles.Body.weight,\n    include.lowest = TRUE\n    )\n```\n:::\n\n\n\n\n\n\nLet’s check how many observations are present in each class.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(d.cats$Body.weight.Class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   [2,2.3]  (2.3,2.7] (2.7,3.02] (3.02,3.9] \n        42         40         26         36 \n```\n\n\n:::\n:::\n\n\n\n\n\n\nFit a model with Sex and Body.weight.Class and compute a p-value for both predictors.\n\n#### Answer\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm.cats.bodyClass <- lm(\n    Heart.weight ~ Sex + Body.weight.Class,\n    data = d.cats)\n\ndrop1(lm.cats.bodyClass, test = \"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSingle term deletions\n\nModel:\nHeart.weight ~ Sex + Body.weight.Class\n                  Df Sum of Sq    RSS    AIC F value Pr(>F)    \n<none>                         354.77 139.84                   \nSex                1      0.30 355.06 137.96  0.1166 0.7333    \nBody.weight.Class  3    350.49 705.26 232.78 45.7751 <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\n\nBody.weight.Class seems to play a relevant role, while Sex does not. This is in full agreement with the model we have seen last week where Body.weight was taken as a continuous predictor.\n\n### Question 5\n\nNow run some contrasts to see whether all pair of levels of the Body.weight.Class predictor differ from each other. Comment on the results.\n\n#### Answer\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(multcomp)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: multcomp\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: mvtnorm\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: survival\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: TH.data\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: MASS\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'TH.data'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:MASS':\n\n    geyser\n```\n\n\n:::\n\n```{.r .cell-code}\nglht.1 <- glht(lm.cats.bodyClass, linfct = mcp(Body.weight.Class = \"Tukey\"))\n##\nsummary(glht.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\t Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Heart.weight ~ Sex + Body.weight.Class, data = d.cats)\n\nLinear Hypotheses:\n                             Estimate Std. Error t value Pr(>|t|)    \n(2.3,2.7] - [2,2.3] == 0       0.7155     0.3813   1.876 0.241722    \n(2.7,3.02] - [2,2.3] == 0      2.4273     0.4382   5.539  < 1e-04 ***\n(3.02,3.9] - [2,2.3] == 0      4.6086     0.4401  10.473  < 1e-04 ***\n(2.7,3.02] - (2.3,2.7] == 0    1.7118     0.4042   4.235 0.000222 ***\n(3.02,3.9] - (2.3,2.7] == 0    3.8932     0.3816  10.202  < 1e-04 ***\n(3.02,3.9] - (2.7,3.02] == 0   2.1814     0.4166   5.236  < 1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n```\n\n\n:::\n:::\n\n\n\n\n\n\n### Question 6\n\nAsk generative AI to provide the interpretation of\n- the coefficients from a linear model\n- the p-values from a linear model\n\nand compare it with the definitions you find in the lecture materials. Do you think they are different in any way? Which one is easier for you to understand?\n\n#### Answer\n\nPrompt:\n\n```txt\nProvide a interpretation of the coefficients and the p-values from a linear model\n```\n> Note: Used Gemeni 3 Fast\n\nAnswer (excerpt) :\n\n```txt\nInterpreting a linear model is all about understanding the \"story\" the data is telling. When you run a regression, you’re essentially trying to find the best-fitting line through your data points[...]. The p-value tells you whether the relationship you see in the coefficient is statistically significant or if it could have just happened by random chance.[...]\n```\n\nThe general statement is accurate, although dividing p-values into “significant” and “not significant” is very bad practice.\n",
    "supporting": [
      "mpm1_exercises_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}